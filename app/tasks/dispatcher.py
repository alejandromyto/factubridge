"""
app/tasks/dispatcher.py

CAPA 3: Dispatcher de eventos outbox (Worker: dispatcher)

Responsabilidad:
- Leer eventos pendientes (FIFO por created_at)
- Encolar en worker AEAT con retry policy
- Marcar como 'encolado' en transacci√≥n SEPARADA

Garant√≠as:
- FIFO estricto: ORDER BY created_at (cadena hash respetada)
- Transacci√≥n INDEPENDIENTE del orquestador
- Si falla, eventos siguen en 'pendiente' (reintento autom√°tico)
- SELECT FOR UPDATE SKIP LOCKED (concurrencia segura)

Ejecutar: Cada 10 segundos v√≠a Celery Beat
"""

import json
import logging
from typing import List, cast

from celery import Task
from sqlalchemy import select, update
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.orm import Session

from app.core.logging.logging_context import set_correlation_id
from app.domain.models.models import (
    EstadoLoteEnvio,
    EstadoOutboxEvent,
    LoteEnvio,
    OutboxEvent,
)
from app.domain.services.outbox_service import OutboxService
from app.infrastructure.database import session_factory_sync
from app.tasks.decorators import typed_task

logger = logging.getLogger(__name__)


@typed_task
def dispatch_outbox_event(
    batch_size: int = 10, correlation_id: str | None = None
) -> None:
    """
    Dispatcher: lee eventos pendientes y los encola al worker AEAT.

    GARANT√çA FIFO CR√çTICA (Art. 12):
    - ORDER BY created_at ASC: respeta orden de creaci√≥n
    - Cadena hash nunca se rompe por procesamiento fuera de orden

    Args:
        batch_size: N√∫mero m√°ximo de eventos a procesar por ejecuci√≥n

    Flujo:
    1. SELECT FOR UPDATE SKIP LOCKED (eventos pendientes, FIFO)
    2. Para cada evento:
       a. Encolar en worker AEAT con retry policy
       b. Marcar evento y lote como ENCOLADO
    3. COMMIT (transacci√≥n SEPARADA del orquestador)

    Ejecutar: Cada 10 segundos v√≠a Celery Beat
    """
    logger.info("=== Dispatcher outbox iniciado ===")

    stats = {
        "leidos": 0,
        "encolados": 0,
        "errores": 0,
    }

    db: Session = session_factory_sync()

    try:
        # PASO 1: Leer eventos pendientes (FIFO, con lock)
        eventos: List[OutboxEvent] = list(
            db.execute(
                select(OutboxEvent)
                .where(OutboxEvent.estado == EstadoOutboxEvent.PENDIENTE)
                .order_by(
                    OutboxEvent.created_at.asc(), OutboxEvent.id.asc()
                )  # FIFO cr√≠tico
                .limit(batch_size)
                .with_for_update(skip_locked=True)  # Concurrencia segura
            )
            .scalars()
            .all()
        )

        stats["leidos"] = len(eventos)

        if not eventos:
            logger.debug("No hay eventos pendientes para despachar")
            return

        logger.info(f"Procesando {stats['leidos']} eventos pendientes")

        # PASO 2: Encolar cada evento en worker AEAT
        servicio_outbox = OutboxService(db)

        from app.tasks.worker_aeat import enviar_lote_aeat

        for evento in eventos:
            try:
                # Parsear payload
                payload = json.loads(evento.payload)
                lote_id = payload["lote_id"]
                correlation_id = payload.get("correlation_id")
                set_correlation_id(correlation_id)

                # Encolar en worker AEAT con retry policy agresiva
                cast(Task, enviar_lote_aeat).apply_async(
                    args=[lote_id, evento.id],
                    kwargs={"correlation_id": correlation_id},
                    retry=True,
                    retry_policy={
                        "max_retries": evento.max_intentos,
                        "interval_start": 10,  # 10 segundos
                        "interval_step": 30,  # +30s por intento
                        "interval_max": 300,  # m√°ximo 5 minutos
                    },
                )
                # Lote ENCOLADO
                db.execute(
                    update(LoteEnvio)
                    .where(LoteEnvio.id == evento.lote_id)
                    .values(estado=EstadoLoteEnvio.ENCOLADO)
                )
                # Evento ENCOLADO (flush, NO commit todav√≠a)
                servicio_outbox.marcar_encolado(evento.id)
                stats["encolados"] += 1

                logger.info(
                    f"üì§ Evento {evento.id} encolado para lote {lote_id} "
                    f"(instalaci√≥n {evento.instalacion_sif_id})"
                    f" | correlation_id={correlation_id}"
                )

            except json.JSONDecodeError as e:
                stats["errores"] += 1
                logger.error(f"‚ùå Error parseando payload del evento {evento.id}: {e}")
                # Marcar como error y continuar
                servicio_outbox.marcar_error(evento.id, f"Payload inv√°lido: {e}")

            except Exception as e:
                stats["errores"] += 1
                logger.error(
                    f"‚ùå Error encolando evento {evento.id}: {e}",
                    exc_info=True,
                )
                # Continuar con otros eventos
                continue

        # PASO 3: Commit de todos los cambios de estado
        db.commit()

        logger.info(
            f"‚úÖ Dispatcher commit exitoso: {stats['encolados']} eventos encolados"
        )

    except SQLAlchemyError as e:
        # Error de BD: rollback (eventos vuelven a 'pendiente')
        db.rollback()
        logger.error(
            f"‚ùå Error de BD en dispatcher (rollback): {e}",
            exc_info=True,
        )
        # No propagar error: siguiente ejecuci√≥n lo reintentar√°

    except Exception as e:
        # Error inesperado: rollback
        db.rollback()
        logger.error(
            f"‚ùå Error inesperado en dispatcher (rollback): {e}",
            exc_info=True,
        )

    finally:
        db.close()
        logger.debug("Sesi√≥n cerrada en dispatcher")

    logger.info(
        f"=== Dispatcher completado === | "
        f"Le√≠dos: {stats['leidos']} | "
        f"Encolados: {stats['encolados']} | "
        f"Errores: {stats['errores']}"
    )
